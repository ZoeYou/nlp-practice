{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "##  Synsets for a word in WordNet\n",
    "*WordNet* is lexical database i.e. dictionary for the English language, specifically designed for natural language processing.\n",
    "\n",
    "**Synset** is a special kind of a simple interface that is present in NLTK to look up words in WordNet. \n",
    "\n",
    "Synset instances are the groupings of synonymous words that express the same concept. Some of the words have only one Synset and some have several."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/zuoyou/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "# use a taxonomy like WordNet that has hypernyms (is-a) relationships\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Synset('procyonid.n.01'),\n",
       " Synset('carnivore.n.01'),\n",
       " Synset('placental.n.01'),\n",
       " Synset('mammal.n.01'),\n",
       " Synset('vertebrate.n.01'),\n",
       " Synset('chordate.n.01'),\n",
       " Synset('animal.n.01'),\n",
       " Synset('organism.n.01'),\n",
       " Synset('living_thing.n.01'),\n",
       " Synset('whole.n.02'),\n",
       " Synset('object.n.01'),\n",
       " Synset('physical_entity.n.01'),\n",
       " Synset('entity.n.01')]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "panda = wn.synset('panda.n.01')\n",
    "hyper = lambda s: s.hypernyms()\n",
    "list(panda.closure(hyper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "car1 = wn.synset('car.n.01')\n",
    "car2 = wn.synset('car.n.02')\n",
    "car3 = wn.synset('car.n.03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "a motor vehicle with four wheels; usually propelled by an internal combustion engine\na wheeled vehicle adapted to the rails of railroad\nthe compartment that is suspended from an airship and that carries personnel and the cargo and the power plant\n"
     ]
    }
   ],
   "source": [
    "print(car1.definition())\n",
    "print(car2.definition())\n",
    "print(car3.definition())"
   ]
  },
  {
   "source": [
    "## Word Embedding using Word2Vec"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all necessary modules\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import gensim \n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Reads ‘alice.txt’ file \n",
    "sample = open(\"alice.txt\", \"r\") \n",
    "s = sample.read() \n",
    "\n",
    "# Replaces escape character with space \n",
    "f = s.replace(\"\\n\", \" \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/zuoyou/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "data = [] \n",
    "\n",
    "#  iterate through each sentence in the file \n",
    "for i in sent_tokenize(f): \n",
    "    temp = [] \n",
    "      \n",
    "    # tokenize the sentence into words \n",
    "    for j in word_tokenize(i): \n",
    "        temp.append(j.lower()) \n",
    "  \n",
    "    data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cosine similarity between 'alice' and 'hatter' - CBOW :  0.99925053\nCosine similarity between 'alice' and 'rabbit' - CBOW :  0.9990961\n"
     ]
    }
   ],
   "source": [
    "# Create CBOW model \n",
    "model1 = gensim.models.Word2Vec(data, \n",
    "                                min_count = 20,  # ignores all words with total absolute frequency lower than this - (2, 100)\n",
    "                                size = 100,     # Dimensionality of the feature vectors. - (50, 300)         \n",
    "                                window = 5)     # The maximum distance between the current and predicted word within a sentence\n",
    "\n",
    "# Print results \n",
    "print(\"Cosine similarity between 'alice' \" + \n",
    "               \"and 'hatter' - CBOW : \", \n",
    "    model1.similarity('alice', 'hatter')) \n",
    "      \n",
    "print(\"Cosine similarity between 'alice' \" +\n",
    "                 \"and 'rabbit' - CBOW : \", \n",
    "      model1.similarity('alice', 'rabbit')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cosine similarity between 'alice' and 'hatter' - Skip Gram :  0.9917865\nCosine similarity between 'alice' and 'rabbit' - Skip Gram :  0.95670986\n"
     ]
    }
   ],
   "source": [
    "# Create Skip Gram model \n",
    "model2 = gensim.models.Word2Vec(data, min_count = 20, size = 100, \n",
    "                                             window = 5, sg = 1) \n",
    "\n",
    "# Print results \n",
    "print(\"Cosine similarity between 'alice' \" +\n",
    "          \"and 'hatter' - Skip Gram : \", \n",
    "    model2.similarity('alice', 'hatter')) \n",
    "      \n",
    "print(\"Cosine similarity between 'alice' \" +\n",
    "            \"and 'rabbit' - Skip Gram : \", \n",
    "      model2.similarity('alice', 'rabbit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}