{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Statistical-models\" data-toc-modified-id=\"Statistical-models-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Statistical models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Part-of-speech\" data-toc-modified-id=\"Part-of-speech-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Part-of-speech</a></span></li><li><span><a href=\"#Syntactic-Denpendency\" data-toc-modified-id=\"Syntactic-Denpendency-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Syntactic Denpendency</a></span></li><li><span><a href=\"#Named-Entity\" data-toc-modified-id=\"Named-Entity-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Named Entity</a></span></li><li><span><a href=\"#spacy.explain-method\" data-toc-modified-id=\"spacy.explain-method-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>spacy.explain method</a></span></li></ul></li><li><span><a href=\"#Rule-base-matching\" data-toc-modified-id=\"Rule-base-matching-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Rule-base matching</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-operaters-and-quantifiers\" data-toc-modified-id=\"Using-operaters-and-quantifiers-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Using operaters and quantifiers</a></span></li></ul></li><li><span><a href=\"#Data-Structures\" data-toc-modified-id=\"Data-Structures-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Data Structures</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the english language class\n",
    "from spacy.lang.en import English \n",
    "\n",
    "# create the nlp object \n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- contains the processing pipeling\n",
    "- includes language-specific rules for tokenization etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "world\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "# created by precessing a string of text with the nlp object \n",
    "doc = nlp(\"Hello world!\")\n",
    "\n",
    "# Iterate over tokens in a Doc \n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens represent words or punctuations in a document. We can index into the doc to get a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index into the doc to get a single token\n",
    "token = doc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world\n"
     ]
    }
   ],
   "source": [
    "# get the token text via .text attribute\n",
    "print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A span object is a slice of a document consisting of one or more tokens. \n",
    "\n",
    "**It's only a view of the tokens and it doesn't contain any data itself.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world!\n"
     ]
    }
   ],
   "source": [
    "# A slice from the doc is a Span Object\n",
    "span = doc[1:3]\n",
    "# get the span text via .text attribute\n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lexical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"It costs $5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  [0, 1, 2, 3, 4]\n",
      "Text:  ['It', 'costs', '$', '5', '.']\n",
      "is_alpha:  [True, True, False, False, False]\n",
      "is_punct:  [False, False, False, False, True]\n",
      "like_num:  [False, False, False, True, False]\n"
     ]
    }
   ],
   "source": [
    "print(\"Index: \", [token.i for token in doc])\n",
    "print(\"Text: \", [token.text for token in doc])\n",
    "\n",
    "print(\"is_alpha: \", [token.is_alpha for token in doc])\n",
    "print(\"is_punct: \", [token.is_punct for token in doc])\n",
    "print(\"like_num: \", [token.like_num for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage found: 60\n",
      "percentage found: 4\n"
     ]
    }
   ],
   "source": [
    "# an example using 'like_num' to find percentages in a text\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(\n",
    "    \"In 1990, more than 60% of people in East Asia were in extreme poverty. \"\n",
    "    \"Now less than 4% are.\"\n",
    ")\n",
    "\n",
    "# Iterate over the tokens in the doc\n",
    "for token in doc:\n",
    "    # Check if the token resembles a number\n",
    "    if token.like_num:\n",
    "        # Get the next token in the document\n",
    "        next_token = doc[token.i + 1]\n",
    "        # Check if the next token's text equals \"%\"\n",
    "        if next_token.text == \"%\":\n",
    "            print(\"percentage found:\", token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are statistical models?\n",
    "\n",
    "* Enable spaCY to predict liguistic attributes in context \n",
    "\n",
    "    * Part-of-speech tags\n",
    "    * Syntactic dependencies \n",
    "    * Named entities\n",
    "    \n",
    "* Trained on labeled example texts\n",
    "* Can be updated with more examples to fine-tune predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-trained packages\n",
    "# ! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "\n",
    "# load the small English model \n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another pre-trained model: `en_vectors_web_lg`\n",
    "\n",
    "It has broader coverage by maintaining morphological information somewhat resulting in more distinct tokens as they are both trained on the common crawl corpus but have a different number of tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Binary weights\n",
    "* Vocabulary \n",
    "* Meta information (language, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She PRON\n",
      "ate VERB\n",
      "the DET\n",
      "pizza NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "# Predicting part-of-speech tags\n",
    "\n",
    "# load the small English model \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process a text \n",
    "doc = nlp(\"She ate the pizza.\")\n",
    "\n",
    "# Iterate over the tokens\n",
    "\n",
    "for token in doc: \n",
    "    # Print the text and the predicted part-of-speech tag\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In spaCY, attributes we turns into string usually ends with underline. Attributes without underline will turn into integer ID values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She 95\n",
      "ate 100\n",
      "the 90\n",
      "pizza 92\n",
      ". 97\n"
     ]
    }
   ],
   "source": [
    "for token in doc: \n",
    "    # Print the text and the predicted part-of-speech tag\n",
    "    print(token.text, token.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic Denpendency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She PRON nsubj ate\n",
      "ate VERB ROOT ate\n",
      "the DET det pizza\n",
      "pizza NOUN dobj ate\n",
      ". PUNCT punct ate\n"
     ]
    }
   ],
   "source": [
    "# Predicting syntactic dependencies\n",
    "\n",
    "for token in doc: \n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"0ee9c72e58f1418bbd557d55c134f6fd-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">She</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">ate</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">pizza.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0ee9c72e58f1418bbd557d55c134f6fd-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0ee9c72e58f1418bbd557d55c134f6fd-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0ee9c72e58f1418bbd557d55c134f6fd-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0ee9c72e58f1418bbd557d55c134f6fd-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0ee9c72e58f1418bbd557d55c134f6fd-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0ee9c72e58f1418bbd557d55c134f6fd-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the dependencies\n",
    "from spacy import displacy \n",
    "\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "U.K ORG\n",
      "$1 billion MONEY\n"
     ]
    }
   ],
   "source": [
    "# Predicting Named Entities\n",
    "\n",
    "# Process a text \n",
    "doc = nlp(\"Apple is looking at buying U.K startup for $1 billion.\")\n",
    "\n",
    "# Iterate over the predicted entities\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and its labels \n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is looking at buying \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.K\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " startup for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $1 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc,style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spacy.explain method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get quick definitions of the most common tags and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Companies, agencies, institutions, etc.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"ORG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun, proper singular'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"NNP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'direct object'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"dobj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule-base matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why not just regular expressions?\n",
    "\n",
    "* Match on `Doc` objects, not just strings\n",
    "* Match on tokens and token attributes\n",
    "* Use the model's predictions \n",
    "* Example: \"duck\" (verb) vs. \"duck\"(noun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match patterns are lists of dictionaries, each dictionary describes one token. The keys are the token attributes.\n",
    "\n",
    "Some Examples:\n",
    "\n",
    "* Match exact token texts: `[{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]`\n",
    "* Match lexical attributes: `[{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]`\n",
    "* Match any token attributes: `[{\"LEMMA\": \"buy\"}, {\"POS\": \"NOUN\"}]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load a model and create the nlp object \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize the matcher with the shared vocab \n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the pattern to the macher\n",
    "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "\n",
    "# second arg is an optional callback\n",
    "matcher.add(\"IPHONE_PATTERN\", None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process some texts\n",
    "doc = nlp(\"Upcoming iPhone X release data leaked\")\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone X\n"
     ]
    }
   ],
   "source": [
    "# Iterate over matches\n",
    "for match_id, start, end in matches:\n",
    "    # Get the matched span \n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each tuple of matches consist of three elements:\n",
    "\n",
    "* match_id: hash value of the pattern name\n",
    "* start: start index of matched span \n",
    "* end: end index of matched span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching lexical attributes\n",
    "pattern = [\n",
    "    {\"IS_DIGIT\": True},\n",
    "    {\"LOWER\": \"fifa\"},\n",
    "    {\"LOWER\": \"world\"},\n",
    "    {\"LOWER\": \"cup\"},\n",
    "    {\"IS_PUNCT\": True},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"2018 FIFA World Cup: France won!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 FIFA World Cup:\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doc) \n",
    "matcher.add(\"wc_PATTERN\", None, pattern)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching other token attributes\n",
    "\n",
    "pattern = [\n",
    "    {\"LEMMA\": \"love\", \"POS\": \"VERB\"},\n",
    "    {\"POS\": \"NOUN\"},\n",
    "]\n",
    "\n",
    "doc = nlp(\"I loved dogs but now I love cats more.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loved dogs\n",
      "love cats\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doc)\n",
    "matcher.add(\"lp_PATTERN\", None, pattern)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using operaters and quantifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "We can thus define how often a token should be matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [\n",
    "    {\"LEMMA\":\"buy\"},\n",
    "    {\"POS\": \"DET\", \"OP\":\"?\"}, # optional: match 0 or 1 times\n",
    "    {\"POS\": \"NOUN\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'determiner'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"DET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I bought a smartphone. Now I'm buying apps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bought a smartphone\n",
      "buying apps\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doc)\n",
    "matcher.add(\"op_PATTERN\", None, pattern)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Op can have four values:\n",
    "\n",
    "`{\"OP\": \"!\"}` => Negation: match 0 times\n",
    "\n",
    "`{\"OP\": \"?\"}` => Optional: match 0 or 1 times\n",
    "\n",
    "`{\"OP\": \"+\"}` => Match 1 or more times\n",
    "\n",
    "`{\"OP\": \"*\"}` => Match 0 or more times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structures\n",
    "\n",
    "Vocab, Lexemes and StringStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCY stores all kinds of data in `Vocab`. In order to save memory, spaCY encodes all strings to **hash values**.\n",
    "\n",
    "Strings are only stored once in the `StringStore` via `nlp.vocab.strings`.\n",
    "\n",
    "String store: **lookup table** in bothe directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://course.spacy.io/en/chapter2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
